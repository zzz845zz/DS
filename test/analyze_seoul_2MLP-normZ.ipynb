{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from utils import preprocessing as my_prep\n",
    "from utils import regression as my_reg\n",
    "from utils import evaluate as my_eval\n",
    "\n",
    "# Data load\n",
    "\n",
    "data_new = pd.read_csv(\"./data/seoul_preprocessed2_y_nextquarter.csv\")\n",
    "data_new.shape\n",
    "\n",
    "### 분기별로 분할\n",
    "\n",
    "quarters = ['2017_1', '2017_2', '2017_3', '2017_4', '2018_1', '2018_2', '2018_3', '2018_4', '2019_1', '2019_2', '2019_3']\n",
    "datas = {}\n",
    "for q in quarters:\n",
    "    year, quarter = map(int, q.split(\"_\"))\n",
    "    \n",
    "    bool_year = data_new.기준_년_코드==year\n",
    "    bool_quarter = data_new.기준_분기_코드==quarter\n",
    "    datas[q] = data_new[bool_year & bool_quarter] \n",
    "    \n",
    "for key in datas.keys():\n",
    "    print(key, datas[key].shape)\n",
    "\n",
    "# Split train, validate, test\n",
    "\n",
    "trainfiles = ['2017_1', '2017_2', '2017_3', '2017_4', '2018_1', '2018_2', '2018_3']\n",
    "validatefiles = []\n",
    "testfiles = ['2018_4', '2019_1', '2019_2', '2019_3']  # 2019_1, 2019_2, 2019_3, 2019_4 맞추기\n",
    "\n",
    "train, validate, test = my_prep.split_train_val_test_by_file(datas, trainfiles, validatefiles, testfiles, category='편의점')\n",
    "print(train.shape, validate.shape, test.shape)\n",
    "\n",
    "### split x, y\n",
    "\n",
    "#x_header = [x for x in train.columns if '연령대' in x and x.find('연령대')==0]\n",
    "x_header = [x for x in train.columns if '남성연령대' in x or '여성연령대' in x]\n",
    "y_header = ['다음분기_매출_금액']\n",
    "print(x_header, y_header)\n",
    "\n",
    "x_train, y_train = my_prep.split_xy(train, x_header, y_header)\n",
    "# x_validate, y_validate = my_prep.split_xy(validate, x_header, y_header)\n",
    "x_test, y_test = my_prep.split_xy(test, x_header, y_header)\n",
    "\n",
    "print('train', x_train.shape, y_train.shape)\n",
    "# print('validate', x_validate, y_validate)\n",
    "print('test', x_test.shape, y_test.shape)\n",
    "\n",
    "### Option(random split)\n",
    "\n",
    "x_train = np.concatenate((x_train, x_test))\n",
    "y_train = np.concatenate((y_train, y_test))\n",
    "print('train', x_train.shape, y_train.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3)\n",
    "print('train', x_train.shape, y_train.shape)\n",
    "print('test', x_test.shape, y_test.shape)\n",
    "\n",
    "# Normalize\n",
    "\n",
    "### Normalize\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "x_train_scale = scaler.transform(x_train)\n",
    "x_test_scale = scaler.transform(x_test)\n",
    "\n",
    "scaler_y = StandardScaler().fit(y_train)\n",
    "y_train_scale = scaler_y.transform(y_train)\n",
    "y_test_scale = scaler_y.transform(y_test)\n",
    "\n",
    "print('train', x_train_scale.shape, y_train_scale.shape)\n",
    "print('test', x_test_scale.shape, y_test_scale.shape)\n",
    "\n",
    "### Correlation coefficient\n",
    "\n",
    "my_eval.visualize_CorrelCoeff_heatmap(x_train_scale, x_header, figsize=(5, 5))\n",
    "\n",
    "# Training\n",
    "\n",
    "x_train_final, y_train_final = x_train_scale, y_train_scale\n",
    "x_test_final, y_test_final = x_test_scale, y_test_scale\n",
    "\n",
    "model_LR = my_reg.get_model_LinearRegression(x_train_final, y_train_final)\n",
    "model_Elastic = my_reg.get_model_ElasticNet(x_train_final, y_train_final)\n",
    "model_SVR = my_reg.get_model_SVR(x_train_final, y_train_final)\n",
    "\n",
    "# hidden_layers = [512, 256, 4]\n",
    "# model_MLPRegression = my_reg.get_model_MLPRegression(\n",
    "#     x_train_scale, y_train_scale, \n",
    "#     hidden_layers=hidden_layers,\n",
    "#     max_iter=5000,\n",
    "#     alpha=0.0001,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "model_LR.coef_\n",
    "\n",
    "### Keras (Tensorflow 2.2.0)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "    layers.Dense(12, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "model_MLPRegression = build_model(input_shape=[x_train_final.shape[1]])\n",
    "model_MLPRegression.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "epo = 0\n",
    "val_mse = 0\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        global epo\n",
    "        global val_mse\n",
    "        epo = epoch\n",
    "        val_mse = logs['val_mse']\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print('.', end='')\n",
    "            #print(logs)\n",
    "        \n",
    "# epoche 끝날때마다 모델 저장\n",
    "# ModelCheck = ModelCheckpoint(os.path.join('./log', 'MLP_normZ'+'-{epoch:04d}-{val_mse:.4f}.hdf5'), monitor='val_mse', verbose=0, \n",
    "#                          save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# metric의 상승이 멈출때마다 learning rate 낮춤\n",
    "ReduceLR = ReduceLROnPlateau(monitor='val_mse', factor=0.2, mode='auto',\n",
    "                          patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "EarlyStop = EarlyStopping(monitor='val_mse', mode='auto', patience=10, restore_best_weights=True)\n",
    "\n",
    "EPOCHS = 5000\n",
    "\n",
    "history = model_MLPRegression.fit(\n",
    "    x_train_final, y_train_final, \n",
    "    batch_size=32,epochs=EPOCHS, verbose=0,\n",
    "    validation_data = (x_test_final, y_test_final),\n",
    "    callbacks=[PrintDot(), ReduceLR, EarlyStop])\n",
    "\n",
    "model_MLPRegression.save('./log/2MLP_normZ-epoch:%04d-val_mse:%.4f}.hdf5' %(epo, val_mse))\n",
    "\n",
    "model_MLPRegression(x_test_scale[0, :].reshape(1, 12))\n",
    "\n",
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure(figsize=(8,12))\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [MPG]')\n",
    "    plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Val Error')\n",
    "    plt.ylim([0,np.max(hist['val_mae'])+2])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "    plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error')\n",
    "    plt.ylim([0,np.max(hist['val_mse'])+2])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "my_eval.eval_regression(y_test_final, model_LR.predict(x_test_final), model_name='Linear Regression')\n",
    "\n",
    "### ElasticNet\n",
    "\n",
    "my_eval.eval_regression(y_test_final, model_Elastic.predict(x_test_final), model_name='ElasticNet')\n",
    "\n",
    "### SVR\n",
    "\n",
    "my_eval.eval_regression(y_test_final, model_SVR.predict(x_test_final), model_name='SVM Regression')\n",
    "\n",
    "# MLP Regressoin\n",
    "\n",
    "my_eval.eval_regression(y_test_final, model_MLPRegression.predict(x_test_final), model_name='MLP Regression')\n",
    "\n",
    "# 오차 계산\n",
    "\n",
    "def evaluate_error(y_gt, y_pred, title=''):\n",
    "    li_error = []\n",
    "    for i in zip(y_gt, y_pred):\n",
    "        error = (abs(i[0]-i[1])/i[0])\n",
    "        li_error.append(error)\n",
    "\n",
    "    print(sum(li_error), y_pred.shape[0])\n",
    "    print('평균 오차 %.lf%%' %(np.mean(li_error)))\n",
    "    print('최대 오차 %.lf%%' %(np.max(li_error)))\n",
    "    print('최소 오차 %.lf%%' %(np.min(li_error)))\n",
    "\n",
    "    #li_error.sort(reverse=True)\n",
    "    #print('Top 10 오차 %s' %(li_error[:10]))\n",
    "    plt.plot(li_error)\n",
    "    plt.title(title)\n",
    "\n",
    "#### normed\n",
    "y_pred_scale_MLP = model_MLPRegression.predict(x_test_final)\n",
    "y_pred_MLP = scaler_y.inverse_transform(y_pred_scale_MLP)\n",
    "\n",
    "#### non-normed\n",
    "#y_pred_MLP = model_MLPRegression.predict(x_test_final)\n",
    "\n",
    "evaluate_error(y_test[:, 0], y_pred_MLP, title='MLP error')\n",
    "\n",
    "y_pred_scale_LR = model_LR.predict(x_test_final)\n",
    "y_pred_LR = scaler_y.inverse_transform(y_pred_scale_LR)\n",
    "\n",
    "evaluate_error(y_test[:, 0], y_pred_LR, title=\"LR error\")\n",
    "\n",
    "y_pred_scale_Elastic = model_Elastic.predict(x_test_final)\n",
    "y_pred_Elastic = scaler_y.inverse_transform(y_pred_scale_Elastic)\n",
    "\n",
    "evaluate_error(y_test[:, 0], y_pred_Elastic, title='Elastic error')\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "##### 정답 값이 너무 비슷? 몇명만 너무 큼? \n",
    "##### 큰 의미가 없나?\n",
    "\n",
    "plt.plot(y_test)\n",
    "\n",
    "print('MLP', int(scaler_y.inverse_transform([-0.02651767])))\n",
    "print('LR', int(scaler_y.inverse_transform([-0.06412931])))\n",
    "#print('SVR', int(scaler_y.inverse_transform([-0.02651767])))\n",
    "print('Elastic', int(scaler_y.inverse_transform([4.09963574e-10])))    #\n",
    "print('ground truth', y_test[0, 0])\n",
    "\n",
    "# TODO\n",
    "\n",
    "1) 전처리  \n",
    "- 가중치부여    \n",
    "\n",
    "2) 차원축소  \n",
    " - wrapper, PCA    \n",
    "\n",
    "3) 증분  \n",
    " - 회귀 증분?    \n",
    "\n",
    "4) 모델 \n",
    " - LGBM, MLP monitoring  \n",
    "\n",
    "5) 학습/검증 분할\n",
    " - random\n",
    " - k-fold(train,validate)/test\n",
    " - sequence  \n",
    " \n",
    "6) 분석, 결론\n",
    " - MSE, R2\n",
    " - 오차\n",
    " - 시각화 (지도?)\n",
    "\n",
    "버릴건 버려야"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
